{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e87ecd-6edf-4854-a680-3a00443061d6",
   "metadata": {},
   "source": [
    "# Final Homework : Route planning in Zürich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f74662-e3e7-4200-97f1-5929672b455f",
   "metadata": {},
   "source": [
    "## 1. Initializing the environment (Spark, HIVE, packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1a291-46cd-482f-a6e3-a0c6bad9d087",
   "metadata": {},
   "source": [
    "This notebook contains the entirety of our work for the final project of the COM-490 course. The aim is to build a robust journey planner in Zürich's area, allowing a user to enquire for an arrival time and a Q value (besides both departure and arrival stop), for which we should output a list of routes arriving no later than the enquiried arrival time, and with a probability of completing the journey being larger than this Q value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882c1be-af81-43b2-859e-fb43fe162379",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <strong>Warning!</strong> Initializing and running a PySpark session is not necessarely needed if you only want to run the core algorithm itself. If you however want to retrace how we preprocessed the data and made assumptions, feel free to do so.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5198aa3-f543-4bd4-88bf-bc5a7f0ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "server = \"http://iccluster044.iccluster.epfl.ch:8998\"\n",
    "\n",
    "get_ipython().run_cell_magic(\n",
    "    'spark',\n",
    "    line='config',\n",
    "    cell=\"\"\"{{ \"name\": \"{0}-final-project\",\"executorMemory\": \"4G\", \"executorCores\": 4, \"numExecutors\": 10, \"driverMemory\": \"4G\"}}\"\"\".format(username)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8008f9-2672-4d37-93a6-ebd192e77c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic(\n",
    "    \"spark\", f\"\"\"add -s {username}-final-project -l python -u {server} -k\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f982a-94a6-4114-853e-762a0488bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "print('We are using Spark %s' % spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0d055-c9b2-40ce-a7a6-c6fe3a7d6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "                                                                                                \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4cac0-4025-489d-bd75-51fc41f05450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "                                                                                                \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7ae96-9808-4130-8c27-cdebd4e8548f",
   "metadata": {},
   "source": [
    "We are now ready to start handling the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb56e45-48d3-4eff-8d3a-f351b83c4f05",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c9047-9daf-44b8-95de-00c81c54ea0d",
   "metadata": {},
   "source": [
    "Before going into our exact method about finding the best journeys, we need to process the `istdaten` table as well as the other timetables we are given according to what we are asked to do. We were indeed given some assumptions in order to simplify the journey planning and these will be the ones guiding this data preprocessing step. More precisely, there will be both some spatial and temporal preprocessing steps to fulfill the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3368a-74f7-4a6e-8273-634fa5219131",
   "metadata": {},
   "source": [
    "### 2.1 Loading the timetable data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda4e1b-985f-4306-bd55-7e642bef651e",
   "metadata": {},
   "source": [
    "We first load the plain timetables located in the `/data/sbb/part_csv/timetables/` path. \n",
    "The only preprocessing done in the following cells is to take the tables only for the most recent schedule (Of the 3rd May 2023), as it is the weekly schema we will consider in our work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c787de4-9f2c-461d-9e76-803640e6e85c",
   "metadata": {},
   "source": [
    "Loading the `stops` table that contains the information about the locations of the stops that are documented by the SBB :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b79fe-af72-4822-badb-36bd464ac0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#Loading the stops.txt table\n",
    "stops = spark.read.csv(\"/data/sbb/part_csv/timetables/stops\",header=True)\n",
    "stops = stops.filter((stops.year == 2023) & (stops.month == 5) & (stops.day == 3)).drop(\"year\",\"month\",\"day\")\n",
    "stops.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081a143-7889-49d1-aa7c-7a57114f23cb",
   "metadata": {},
   "source": [
    "Loading the `stop_times` table, containing information about many informations about connections between the stops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c4ed6-8837-4c0d-a70d-1af79f178a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "stop_times = spark.read.csv(\"/data/sbb/part_csv/timetables/stop_times\",header=True)\n",
    "stop_times = stop_times.filter((stop_times.year == 2023) & (stop_times.month == 5) & (stop_times.day == 3)).drop(\"year\",\"month\",\"day\")\n",
    "stop_times.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9200584-2a67-45d1-b698-278a17aea952",
   "metadata": {},
   "source": [
    "Loading the `trips` dataframe, containing metadata about the trips listed by the SBB CFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38940a-e811-454f-b5f2-46f1240e6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "trips = spark.read.csv(\"/data/sbb/part_csv/timetables/trips\",header=True)\n",
    "trips = trips.filter((trips.year == 2023) & (trips.month == 5) & (trips.day == 3)).drop(\"year\",\"month\",\"day\")\n",
    "trips.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3f2d5-8537-4d91-bebc-40ffa32753fe",
   "metadata": {},
   "source": [
    "Finally, loading the `calendar` data that contains information about the regularity/daily patterns of the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660523e-73a4-4d4b-9945-82e7aa058aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "calendar = spark.read.csv(\"/data/sbb/part_csv/timetables/calendar\",header=True)\n",
    "calendar = calendar.filter((calendar.year == 2023) & (calendar.month == 5) & (calendar.day == 3)).drop(\"year\",\"month\",\"day\")\n",
    "calendar.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa464fe-938c-474b-acf8-7e535478d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "routes = spark.read.csv(\"/data/sbb/part_csv/timetables/routes\",header=True)\n",
    "routes = routes.filter((routes.year == 2023) & (routes.month == 5) & (routes.day == 3)).drop(\"year\",\"month\",\"day\")\n",
    "routes.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99163f37-ba86-4d5e-b0c3-c0427d9fe9cf",
   "metadata": {},
   "source": [
    "### 2.1 Spatial processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a5210-2c8f-4219-9fd7-67f0990df9a5",
   "metadata": {},
   "source": [
    "#### 2.1.1 Filtering the stops inside a 15km radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd19c9a-93ed-4b2e-bab0-c393a1b1cb62",
   "metadata": {},
   "source": [
    "One of the first very important steps is to limit the stops we're studying to the ones belonging to a 15km radius around Zürich. We will thus define two quick functions that will help us retrieve the distance between the coordinates of a certain point in space and Zürich's. \n",
    "\n",
    "The inspiration for the code has been taken from https://stackoverflow.com/questions/24680247/check-if-a-latitude-and-longitude-is-within-a-circle-google-maps and quickly adapted to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01134f-c7a4-4403-a6d7-acaf7331ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "def distance_computer(ctr_lat,ctr_lon,pt_lat,pt_lon) :\n",
    "    \"\"\" Computes the distance (euclidean) between (lat,lon) pairs of two points in space.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ctr_lat (double): Latitude of the center point,\n",
    "    ctr_lon (double): Longitude of the center point,\n",
    "    pt_lat (double): Latitude of a certain point of interest,\n",
    "    pt_lon (double): Longitude of a certain point of interest,\n",
    "    earth_circ(double) : The circumference of the earth, used for geometry computations.\n",
    "\n",
    "    Returns:\n",
    "    dist_in_km : The distance in km between the center point and the point of interest\n",
    "\n",
    "    \"\"\"\n",
    "    earth_circ = 40075.0\n",
    "    km_per_deg_lat = earth_circ / 360.0\n",
    "    km_per_deg_lon = math.cos(math.pi * float(ctr_lat) / 180.0) * km_per_deg_lat\n",
    "    dx = np.abs(float(ctr_lon)-float(pt_lon)) * km_per_deg_lon\n",
    "    dy = np.abs(float(ctr_lat)-float(pt_lat)) * km_per_deg_lat\n",
    "    dist_in_km = math.sqrt(dx*dx + dy*dy)\n",
    "    return(dist_in_km)\n",
    "\n",
    "def dist_from_zurich(stop_lat,stop_lon) :\n",
    "    \"\"\" Computes the distance (euclidean) between Zürich and a certain point in space.\n",
    "\n",
    "    Parameters:\n",
    "    pt_lat (double): Latitude of a certain stop/point of interest,\n",
    "    pt_lon (double): Longitude of a certain stop/point of interest,\n",
    "\n",
    "    Returns:\n",
    "    zur_dist : The distance in km between Zürich and the point we are interested in.\n",
    "    \"\"\"\n",
    "    earth_circ = 40075\n",
    "    zur_lat = 47.378177\n",
    "    zur_lon = 8.540192\n",
    "    dist_from_zurich = distance_computer(zur_lat,zur_lon,stop_lat,stop_lon)\n",
    "    return(dist_from_zurich) \n",
    "\n",
    "#Creating a user-defined function based our distance computing method\n",
    "dist_from_zur = F.udf(dist_from_zurich, T.FloatType())\n",
    "compute_distance = F.udf(distance_computer,T.FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc15429-25c8-4679-8a02-99e0f51ad732",
   "metadata": {},
   "source": [
    "We first filter the `stops` dataframe to obtain`close_stops`, which only contains the stops within a $15km$ radius around Zurich. These close stops will be the stops in which the user will be able to choose a source and a destination stop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1197c-6c07-42e1-b24d-0fe1d757e1d5",
   "metadata": {},
   "source": [
    "The `dist_from_zur` function first allows us to first filter the `stops` table in keep only the `STOP_ID`s that are inside this $15$km radius around Zürich's coordinates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabdeb4-34c1-4c90-b4d8-232bd304bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#Filter the stops.txt based (not created yet) table to keep only the ones where the dist_from_zur function outputs a number that is <15.\n",
    "filtered_stops = stops.withColumn(\"distance_from_zur\",dist_from_zur(stops.stop_lat,stops.stop_lon))\n",
    "close_stops = filtered_stops.filter(F.col(\"distance_from_zur\") <= 15.0)\n",
    "close_stops.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870eaba-dab3-4b6d-b296-c4883f074e6d",
   "metadata": {},
   "source": [
    "Now that we have our close stops `STOP_ID`s, we filter the `stop_times` dataframe in the same manner :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ff7b0-f0ff-47a1-b5d7-e5f7f3ccada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#Filter the stop_times based table in order to only keep the trips where the STOP_IDs are the same as the ones just found\n",
    "# in the cell above.\n",
    "\n",
    "close_stop_times = stop_times.join(close_stops.select(\"stop_id\"), on=\"stop_id\",how = \"inner\").drop(\"pickup_type\",\"drop_off_type\")\n",
    "close_stop_times.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2b428-5eb5-44fe-8840-2066846e5e8e",
   "metadata": {},
   "source": [
    "#### 2.1.2 Trying to retrieve transfer stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84158b-a9ec-4bf0-886f-720321aa3fef",
   "metadata": {},
   "source": [
    "However, one of the assumptions of our problem is that we may also use some stops outside the $15km$ radius as transfer stops. Therefore, by removing all the stops further than $15km$ than Zürich, we also rule out these transfer-only stops. It is for instance likely that some of these trips will leave this $15km$ radius for one or two stops before coming back into the limits of our problem. \n",
    "\n",
    "Implementing this is not that easy, so we decided to focus on a certain type of trips. More precisely, we look for all of the trips passing by our close stops but that can not be completed only with stops located within the 15km radius: they go, at some point, slightly out of this 15km radius.\n",
    "\n",
    "Concretely, we aim to find the trips for which the `STOP_SEQUENCE` ids have a missing entry when considering only the close stops filtered earlier. This way, we aim to identify the stops that are most likely not very far away from the $15km$ radius and that are crossed by some trips that go back into the 15km radius : they can thus serve as transfer stops. We illustrate the idea in the figure below :\n",
    "\n",
    "<img src=\"../figs/Outside_the_radius.png\" width=\"800\"/>\n",
    "\n",
    " _Figure 1._ Illustration of the stops found by our method.\n",
    " The blue circle represents the 15km radius around Zürich, an example trip with one stop outside the 15km radius is shown in orange, with the stop that we will retrieve and add to our stops database is circled in black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5554723-f257-4d30-8497-5aee96c5b9eb",
   "metadata": {},
   "source": [
    "We thus want to identify the trips that quickly go out of the 15km radius before going back in, if any. We define a `trip_id` based window, ordered by `stop_sequence`. Using the lead and lag functions, for each `stop_sequence`, we define new columns with the `stop_sequence` value of the previous/next stop on the trip. That way, by quickly looking at the difference between the current and previous/next `stop_sequence` value, we can easily tell if there is one `stop_sequence` is missing from the trip (a jump from 3 to 5, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a1f3c-aaa9-4f69-88df-c6cc9a1dec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "close_stop_times = close_stop_times.withColumn('stop_sequence',F.col('stop_sequence').cast('int'))\n",
    "trip_window = Window.partitionBy('trip_id').orderBy('stop_sequence')\n",
    "\n",
    "\n",
    "lag_stop_seq = F.lag(F.col(\"stop_sequence\")).over(trip_window)\n",
    "lead_stop_seq = F.lead(F.col(\"stop_sequence\")).over(trip_window)\n",
    "\n",
    "tmp_lag_lead = close_stop_times.withColumn('lag_stop_seq',lag_stop_seq)\\\n",
    "                               .withColumn('lead_stop_seq',lead_stop_seq)\\\n",
    "                               .withColumn('curr_lag_diff', F.col('stop_sequence')-F.col('lag_stop_seq'))\\\n",
    "                               .withColumn('curr_lead_diff', F.col('lead_stop_seq')-F.col('stop_sequence'))\n",
    "\n",
    "tmp_lag_lead.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3394e02-091c-432a-bfb1-3b7eca2391af",
   "metadata": {},
   "source": [
    "We then only select the ones for which the difference between the current `stop_sequence` value and the previous/next one is equal to 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d57daa-1008-4d94-a6ab-c6879e7f6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "missing_stop_seq_trips  = tmp_lag_lead.filter(\n",
    "    ((F.col('curr_lag_diff') == 2) | (F.col('curr_lead_diff') == 2 )) &\n",
    "      ((F.col('curr_lag_diff').isNotNull()) & (F.col('curr_lead_diff').isNotNull()))\n",
    ").orderBy('trip_id')\n",
    "\n",
    "missing_stop_seq_trips.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fff73b-690a-481d-947c-e1a5213c3d52",
   "metadata": {},
   "source": [
    "We retrieve, for each `trip_id`, the missing `stop_sequence`  values (They're only in two different columns previous/next in the output of the cell below for more simplicity when manipulating the PySpark dataframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181c37e-6469-4c0e-90a8-935dd385f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "missing_stops = missing_stop_seq_trips.withColumn('prev_missing_stop_seq', F.when(F.col('curr_lag_diff') == 2, F.col('stop_sequence') -1))\\\n",
    "                                      .withColumn('next_missing_stop_seq', F.when(F.col('curr_lead_diff') == 2, F.col('stop_sequence') +1))\\\n",
    "                                      .drop(\"stop_id\",\"stop_sequence\",\"arrival_time\",\"departure_time\",\"lag_stop_seq\",\"lead_stop_seq\",\"curr_lag_diff\",\n",
    "                                           \"curr_lead_diff\")\n",
    "missing_stops.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17881da7-932b-4362-9b67-7ed0d7a3bb7a",
   "metadata": {},
   "source": [
    "Now that we know, for each trip, exactly which `stop_sequence` value is missing, we identify all the stops corresponding to these missing values : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c57a9-c293-4ecb-a7ec-01bc481c3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "transfer_stops = stop_times.join(missing_stops,on = \"trip_id\", how = \"inner\")\\\n",
    "                              .filter( (stop_times.stop_sequence == missing_stops.prev_missing_stop_seq) |\n",
    "                                       (stop_times.stop_sequence == missing_stops.next_missing_stop_seq))\\\n",
    "                              .orderBy(\"trip_id\").select(\"stop_id\").distinct()\n",
    "\n",
    "transfer_stops.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef72afb-6706-49bf-a61e-719a4b63f360",
   "metadata": {},
   "source": [
    "We thus only obtain 4 distinct stops, but through which many different trips go in and out the $15km$ radius. These stops can still therefore be interesting to add to our pool of stops through which the users can travel (but that can not be source or departure stops). \n",
    "\n",
    "Let's double check if these transfer stops are indeed further than $15km$ from Zürich :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b13e2d-a889-406a-a7af-ea17c3e71a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "transfer_stops_dists = stops.join(transfer_stops, on = \"stop_id\" , how = \"inner\")\n",
    "transfer_stops_dists = transfer_stops_dists.withColumn(\"distance_from_zur\",dist_from_zur(transfer_stops_dists.stop_lat,transfer_stops_dists.stop_lon))\n",
    "transfer_stops_dists.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b48acd-f012-4ff2-9970-638238d3cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "all_stops = close_stops.union(transfer_stops_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96bd71-6a71-4117-bf0c-0f7c0a54907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "all_stops.repartition(1).write.option('header',True).csv(\"/user/rochepea/all_stops.csv\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb6d2a-646d-4f85-af24-887569d0e4fb",
   "metadata": {},
   "source": [
    "As expected, our transfer-only stops are indeed just outside the 15km radius. We then add them these stops to our `close_stops` and thus our `close_stop_times`, in order to obtain the `valid_stop_times` containing all the trips/stops that we decide to keep based on the spatial assumptions we were given :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b58fa5-4aa3-4b91-9ac4-9672f74103c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "transfer_stop_times = stop_times.join(transfer_stops, on = \"stop_id\", how=\"inner\").drop(\"pickup_type\",\"drop_off_type\")\n",
    "transfer_stop_times.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374689e9-86f8-45e7-8b67-dab47c5d82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "valid_stop_times = close_stop_times.union(transfer_stop_times)\n",
    "valid_stop_times.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a37605-b54f-4f2f-b81e-2e1ef0e699b3",
   "metadata": {},
   "source": [
    "### 2.2 Temporal processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0485f-d252-4b35-bf2c-c21ab931944c",
   "metadata": {},
   "source": [
    "As stated in the project description, we also need to be only considering journeys that are on reasonable hours of a typical business day. \n",
    "First, we use the `calendar` table to filter all the `SERVICE_ID`s, i.e group of trips that take place on normal business days, from Monday to Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e193a48-63e4-4ff6-97d7-7d4dcd59c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Filter the calendar.txt based table to keep only the group of trips only happening on business days.\n",
    "usual_calendar = calendar.filter((F.col(\"monday\") == 1) &\n",
    "                                 (F.col(\"tuesday\") == 1) &\n",
    "                                 (F.col(\"wednesday\") == 1) &\n",
    "                                 (F.col(\"thursday\") == 1) &\n",
    "                                 (F.col(\"friday\") == 1) & \n",
    "                                 (F.col(\"saturday\") == 0) &\n",
    "                                 (F.col(\"sunday\") == 0))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a82e9d-aeb9-40fe-8c04-a683168c692a",
   "metadata": {},
   "source": [
    "We then join the `calendar` table to the `trips` one based on the recently filtered `SERVICE_ID` key to obtain the `regular_trips` table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abddbf0-3b2c-448f-9b04-1373030c2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Build the regular_trips table \n",
    "regular_trips = trips.join(usual_calendar, on = \"service_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e2dca-1a70-494b-93b7-d00f8ea27a7c",
   "metadata": {},
   "source": [
    "This first joined table thus only contains the group of trips taking place from Monday to Friday on a daily basis, i.e the regular ones (as well as the other columns of both the `calendar` and `trips` table, but we will get back to them later). \n",
    "\n",
    "Now, let us only select the specific trips that take place in reasonable hours. We decide to define these reasonable hours as being from 7AM to 9PM and we thus filter the `close_stop_times` accordingly :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76513b-f13f-4b48-ad00-c0cebe90b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Filter the stop_times table to keep only the rows where (DEPARTURE_TIME & ARRIVAL_TIME) belong to [7AM,9PM]\n",
    "valid_stop_times = valid_stop_times.withColumn('departure_time',F.date_format(F.to_timestamp('departure_time', \"HH:mm:ss\"),\"HH:mm:ss\"))\\\n",
    "                                   .withColumn('arrival_time',F.date_format(F.to_timestamp('arrival_time', \"HH:mm:ss\"),\"HH:mm:ss\"))\n",
    "regu_valid_stop_times = valid_stop_times.filter((F.hour(\"departure_time\") >= 7) &\n",
    "                                                (F.hour(\"arrival_time\") >= 7) &\n",
    "                                                (F.hour(\"departure_time\") <= 21) &\n",
    "                                               (F.hour(\"arrival_time\") <= 21)\n",
    "                                               )\n",
    "regu_valid_stop_times.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7ca8c-6abe-4005-aef3-18a2338c8bab",
   "metadata": {},
   "source": [
    "Now, we join the filtered `stop_times` and the `regular_trips` tables with respect to the `TRIP_ID` key, which characterizes the unique instance of a certain trip. This way, we obtain another table `valid_trips` that only contains the trips that travel following a regular basis during the 7AM-9PM shift from Monday to Friday in a 15km (without transfer stops) radius around Zürich : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda79dd9-315d-4539-8f7f-18f2d9d2166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#Build the valid_trips table as explained just above.\n",
    "valid_trips = regu_valid_stop_times.join(regular_trips, on = \"trip_id\", how = \"inner\").drop('trip_headsign','trip_short_name')\n",
    "valid_trips = valid_trips.withColumn('stop_sequence',F.col('stop_sequence').cast('int'))\n",
    "valid_trips.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941f35d-0002-43a3-8b7b-ade70d87adfe",
   "metadata": {},
   "source": [
    "### 2.3 Additional preprocessing :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbe735-d56a-4e7d-a497-51bc521a338e",
   "metadata": {},
   "source": [
    "We use the spatial and temporal preprocessing in order to build three very important tables that will be used in our journey-finding algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee234760-b21d-4bfc-9590-db7ecba69f29",
   "metadata": {},
   "source": [
    "#### 2.3.1 Setting up all the existing connections in the network :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8c15a-ef6f-4012-8f8b-1c6dcc97aa63",
   "metadata": {},
   "source": [
    "We first, based on our `valid_trips` table, define all the connections that link the different stops in the Zürich area. We characterize a connection by the `trip_id` it belongs to, the departure stop and time of the connection as well as the arrival stop and time of the latter. We build the `connections` dataframe in the following manner :\n",
    "\n",
    "\n",
    "- Take our `valid_trips` and define a window that partitions it by the `trip_id`, ordered by `arrival_time`.\n",
    "- Then, thanks to the F.Lead function, for each row, we fetch the `arrival_stop` and the `arrival_time` of the next stop on the trip.\n",
    "- We set the rows with the current trip, stop and departure time, and add these arrival stops and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609b4fb-9c20-4eff-b9e1-8098fbb1811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "trip_window = Window.partitionBy('trip_id').orderBy('arrival_time')\n",
    "arrival_stop = F.lead(\"stop_id\").over(trip_window).alias(\"arrival_stop\")\n",
    "arrival_time = F.lead(\"arrival_time\").over(trip_window).alias(\"arrival_time\")\n",
    "\n",
    "connections = valid_trips.select('trip_id',F.col('stop_id').alias('departure_stop'),'departure_time',arrival_stop,arrival_time)\n",
    "connections = connections.filter(F.col('departure_time').isNotNull() & F.col('arrival_time').isNotNull())\n",
    "connections = connections.orderBy('departure_time')\n",
    "connections.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbdf00-82dd-435a-919c-106cecc60ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%spark\n",
    "#connections.repartition(1).write.option('header',True).csv(\"/user/rochepea/connections.csv\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b4376-40e5-4d94-a0fe-b4de321e5891",
   "metadata": {},
   "source": [
    "#### 2.3.2 Finding all walking paths between our stops :\n",
    "\n",
    "As stated in the project description, we have to take into account the fact that walking from one stop to the other is totally possible. We use the compute_distance function defined earlier on all our valid stops (transfer stops + <15km stops) to only keep the ones closer than 500m from each other. In addition to both stop ids and names, we also retrieve the distance between the two as well as the travel time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75fafc-b7ac-4339-992b-4ef9146522f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "transfer_stops_info = stops.join(transfer_stops, on = 'stop_id', how = 'inner')\n",
    "valid_stops = transfer_stops_info.union(close_stops.drop('distance_from_zur')).drop('location_type','parent_station')\n",
    "\n",
    "\n",
    "tmp_valid_stops = valid_stops.alias('a').crossJoin(valid_stops.alias('b'))\n",
    "\n",
    "\n",
    "tmp_valid_stops = tmp_valid_stops.withColumn(\"distance_btw_stops\",compute_distance(F.col('a.stop_lat'),F.col('a.stop_lon'),F.col('b.stop_lat'),F.col('b.stop_lon')))\n",
    "footpaths = tmp_valid_stops.filter( (F.col(\"distance_btw_stops\") < 0.5) &\n",
    "                  (F.col('a.stop_name') != F.col('b.stop_name')))\\\n",
    "                      .select(F.col('a.stop_id').alias('first_stop_id'),\n",
    "                              F.col('a.stop_name').alias('first_stop_name'),\n",
    "                              F.col('b.stop_id').alias('second_stop_id'),\n",
    "                              F.col('b.stop_name').alias('second_stop_name'),\n",
    "                              F.col('distance_btw_stops').alias('distance'))\n",
    "\n",
    "footpaths = footpaths.withColumn('duration',F.col('distance')/0.05)\n",
    "footpaths.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef844695-3dba-4a03-a5e8-575dc8f6b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%spark\n",
    "#footpaths.repartition(1).write.option('header',True).csv(\"/user/rochepea/footpaths.csv\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e2d5a-af81-4610-8950-710595e0d81e",
   "metadata": {},
   "source": [
    "#### Retrieve the transport types of the trips of our connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c3a1a-69a8-4c99-a308-8ddce23fa639",
   "metadata": {},
   "source": [
    "For vizualisation purposes, we also want to be able to know which transport type each of the `trip_id`s corresponds to (Bus, Train, Metro, etc.)\n",
    "\n",
    "We thus join the `trips` original table based on the unique `trip_id`s present in our connections table. Then, thanks to the `route_id` column for each trip, we look at the corresponding `ROUTE_DESC` column in the `routes` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e08bd3-2586-4d2f-b969-525895e465c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "connections_trips = trips.join(connections, on ='trip_id', how = 'inner')\n",
    "joined_trips = connections_trips.join(routes, on = 'route_id')\n",
    "transport_types = joined_trips.select(connections_trips['trip_id'],routes['route_desc'])\n",
    "transport_types = transport_types.dropDuplicates(['trip_id'])\n",
    "transport_types.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f200a1a-11cd-4051-bd70-970f3da02c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%spark\n",
    "#transport_types.repartition(1).write.option('header',True).csv(\"/user/rochepea/transport_types.csv\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ee094-224f-4731-85d1-710b891a9031",
   "metadata": {},
   "source": [
    "### 2.4 Preparing the delays information with the SBB data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54d8bd-93c3-4ac0-97e5-f6549f171025",
   "metadata": {},
   "source": [
    "In order to take into account the risk of the user missing a certain connection when planning an itinerary, we will use the previous years information from the `istdaten` table to retrieve historical delays for the stops of our network around Zürich. For these delays to be as useful as possible to product a robust journey planner, we will consider the following when building them :\n",
    "\n",
    "- The delays we will base ourselves on are the **arrival delays**, meaning the difference between the expected arrival time and the actual arrival time, for each stop in our network.\n",
    "- For each connection, the delay will most likely depend on the transport type, the day during which the connection is taken and the time during the day as well (peak/off hours). These are all parameters that we will take into account when computing the different delay characteristics (mean,the variance etc.) for each connection.\n",
    "\n",
    "\n",
    "\n",
    "We first load the plain SBB data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb4ec2-4038-426f-a222-2a13bdc386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "sbb_data = spark.read.orc(\"/data/sbb/part_orc/istdaten\")\n",
    "sbb_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cd754-3aa8-4609-8b75-c34c5572619a",
   "metadata": {},
   "source": [
    "We tidy our SBB data by only keeping rows with information that we can use to compute the delays. That is:\n",
    "- the rows with the `betreibstag`,`produkt_id` having valid values,\n",
    "- `an_prognose_status` being `REAL`, `GESCHAETZT` or `PROGNOSE`. Ultimately, we would want to only compute the delays thanks to effective arrival time, but we still keep the other values in case some transport means or stops do not have enough real values to compute the delays, in which case we will use the forecasted or estimated ones.\n",
    "- We also only keep the rows where `ANKUNFTSZEIT` and `AN_PROGNOSE` have valid values, usable to compute delays,\n",
    "- We only keep the trips that have been completed and that are not additional non-regular trips (`FAELLT_AUS_TF` & `ZUSATZFAHRT_TF` = false)\n",
    "- We take the sbb data starting from 2021, as two years of data should be enough to obtain delay estimates and we need some recent data to have a good estimation of the current delays.\n",
    "- We only select the rows where `bpuic` corresponds to valid `STOP_ID`s found earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c40f0f-acf8-4d9d-bbd2-e994bef27b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "valid_stop_ids = valid_trips.select(\"stop_id\").distinct()\n",
    "\n",
    "clean_sbb_data = sbb_data.filter((F.col('betriebstag').like('__.__.____')) &\n",
    "                           (F.col('produkt_id').isNotNull()) &\n",
    "                           (F.length(F.col('produkt_id')) > 0) &\n",
    "                           (F.col('an_prognose_status').isin('PROGNOSE','REAL','GESCHAETZT')) &\n",
    "                           (F.col('ankunftszeit').isNotNull()) &\n",
    "                           (F.length(F.col('ankunftszeit')) > 0) &\n",
    "                           (F.col('an_prognose').isNotNull()) &\n",
    "                           (F.length(F.col('an_prognose')) > 0) &\n",
    "                           (F.col('ab_prognose').isNotNull()) &\n",
    "                           (F.length(F.col('ab_prognose')) > 0) &\n",
    "                           (F.col('faellt_aus_tf') == 'false') &\n",
    "                           (F.col('zusatzfahrt_tf') == 'false') &\n",
    "                           (F.col('year').isin(2021,2022,2023)))\\\n",
    "                           .drop('betreiber_abk','betreiber_name','linien_id','linien_text','umlauf_id','verkehrsmittel_text',\n",
    "                                 'betreiber_id', 'durchfahrt_tf')\\\n",
    "                           .withColumnRenamed('bpuic','stop_id')\n",
    "\n",
    "clean_sbb_data = clean_sbb_data.join(valid_stop_ids, on = \"stop_id\", how = \"inner\")\n",
    "clean_sbb_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2359fa4-c307-4f19-9bec-d6e596967fea",
   "metadata": {},
   "source": [
    "We also want to only compute the delays we need, i.e the ones for the trips running in the $[7AM,9PM]$ interval. We thus modify our sbb_data to only keep the rows where this criteria is verified :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8970d2-873f-483a-84a0-0f7671704461",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "usable_sbb_data = clean_sbb_data.filter(\n",
    "    (F.substring('an_prognose', 12, 2).cast('integer') >= 7) &\n",
    "    (F.substring('an_prognose', 12, 2).cast('integer') <= 21) &\n",
    "    (F.substring('ab_prognose', 12, 2).cast('integer') >= 7) &\n",
    "    (F.substring('ab_prognose', 12, 2).cast('integer') <= 21)\n",
    ")\n",
    "usable_sbb_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79caf7-68e2-4cff-8710-c8d9a4a4a73c",
   "metadata": {},
   "source": [
    "Now that our `sbb_data` has been cleaned for use, we can look at the nature of the arrival times computation status for the different types of transport, i.e if the `AN_PROGNOSE_STATUS` is `REAL`, `PROGNOSE` or `GESCHAETZT`. The aim is to identify any transport type for which using the real measured values of arrival times would not yield enough data to obtain a decent estimate of the delays at the different stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22049090-ed4b-4ad5-96aa-e34c0c831829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Group by 'produkt_id' and pivot on 'an_prognose_status' column\n",
    "count_df = usable_sbb_data.groupBy('produkt_id').pivot('an_prognose_status').count()\n",
    "\n",
    "# Rename the columns for better readability\n",
    "count_df = count_df.withColumnRenamed('REAL', 'real_count') \\\n",
    "                   .withColumnRenamed('PROGNOSE', 'prognose_count') \\\n",
    "                   .withColumnRenamed('GESCHAETZT', 'geschaetzt_count')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "count_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4f69f-844d-4f71-82ed-81df5e97c481",
   "metadata": {},
   "source": [
    "We can observe that for the trains, only using the `REAL` and thus measured arrival times shouldn't be an issue. However, for Trams and Buses, we have even more `PROGNOSE` arrival time status than `REAL` ones. We can therefore decide to keep rows having either `PROGNOSE` or `REAL` an_prognose_status values to compute our delays. We also decide to only keep reasonable delay values $<1h$ and set all negative delays (i.e stop reached before the scheduled time) to 0. We also set the day of the week and the hour during which the connection happens, for the next step of the delays preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bddb1-f93c-459a-904b-00250824de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "usable_sbb_data = usable_sbb_data.withColumn('actual_arr_time',F.unix_timestamp('an_prognose', 'dd.MM.yyyy HH:mm:ss'))\n",
    "usable_sbb_data = usable_sbb_data.withColumn('scheduled_arr_time', F.unix_timestamp('ankunftszeit','dd.MM.yyyy HH:mm'))\n",
    "\n",
    "delays_df = usable_sbb_data.withColumn('arr_delay',(usable_sbb_data.actual_arr_time - usable_sbb_data.scheduled_arr_time)/60)\n",
    "delays_df = delays_df.select('stop_id',F.col('betriebstag').alias('date'),F.col('fahrt_bezeichner').alias('trip_id'),F.col('produkt_id').alias('transport_type'),\n",
    "                             F.col('haltestellen_name').alias('stop_name'),'actual_arr_time','scheduled_arr_time','arr_delay',\n",
    "                             'an_prognose_status')\n",
    "                           \n",
    "delays_df = delays_df.withColumn('arr_delay', F.when(F.col('arr_delay') <0,0).otherwise(F.col('arr_delay')))\n",
    "delays_df = delays_df.filter((F.col('arr_delay') < 60) & (F.col('an_prognose_status').isin('REAL','PROGNOSE')))\n",
    "\n",
    "delays_df = delays_df.withColumn('arrival_hour',F.date_format(F.from_unixtime(delays_df.scheduled_arr_time),'H'))\n",
    "delays_df = delays_df.withColumn('weekday',F.date_format(F.from_unixtime(delays_df.scheduled_arr_time),'EEEE'))\n",
    "\n",
    "delays_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eab469-ed6b-4102-82ce-e5f8cc497f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "std_value_delays = delays_df.select(F.stddev('arr_delay')).first()[0]\n",
    "mean_value_delays = delays_df.select(F.mean('arr_delay')).first()[0]\n",
    "print(mean_value_delays)\n",
    "print(std_value_delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfd27b-e76b-43be-b6a1-57a4b44be77e",
   "metadata": {},
   "source": [
    "These values: std_value_delays and mean_value_delays will be used later to calculate the probability of being late for stop_id without a known delay.\n",
    "In order to avoid rexecting everything, we will simply assign the values that we found to the variables in the function where it's needed: 3.3.3 Delays & Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3b5ca-067c-4cb4-92aa-d6be78f72d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_delays = 1.227\n",
    "std_value_delays = 1.428"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a9701-2ff6-405e-8f94-5b3977eebc76",
   "metadata": {},
   "source": [
    "As previously explained, we now decide to distribute our delays for each arrival stop in function of the transport type, the day of the week and the hour during which the connection takes place. For instance, by taking the `delays_df` just above, 'Kloten Waldeggweg' will have for each transport type, each day of the week and each hour between 7AM and 9PM, a mean delay and a variance of the delays obtained thanks to the historical SBB istdaten data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31f8b5-af89-4865-bbb1-c5919a90ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "delays_stats_df = delays_df.groupBy('stop_id','transport_type','arrival_hour','weekday')\\\n",
    "                  .agg(F.mean('arr_delay').alias('mean_delay'),\n",
    "                       F.stddev('arr_delay').alias('stddev_delay'),\n",
    "                       F.count('arr_delay').alias('sample_size'))\n",
    "delays_stats_df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46612a-7b46-4514-b0c1-90c4faf48803",
   "metadata": {},
   "source": [
    "These lines below are used to test out if, it is logic to take a normal distribution as being the distributions of the delays at each stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd8324-e809-41d1-9801-e8ac3647840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o filtered_delays\n",
    "\n",
    "# Filter delays for the desired group\n",
    "group_filter = (F.col('stop_id') == '8502471') & (F.col('transport_type') == 'Bus') & (F.col('arrival_hour') ==7)  & (F.col('weekday') == 'Friday')\n",
    "filtered_delays = delays_df.filter(group_filter).select('arr_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a78bbb-d243-4d56-9d19-4fe42ec46bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, norm\n",
    "\n",
    "data = filtered_delays['arr_delay']\n",
    "\n",
    "kde = gaussian_kde(data)\n",
    "\n",
    "x = np.linspace(np.min(data), np.max(data), 100)\n",
    "\n",
    "kde_pdf = kde(x)\n",
    "\n",
    "mu, sigma = np.mean(data), np.std(data)\n",
    "norm_pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, kde_pdf, label='KDE')\n",
    "plt.plot(x, norm_pdf, label='Normal Distribution')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Probability Density Function')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2d7ff-dd19-4688-a8a4-093ab26a03bb",
   "metadata": {},
   "source": [
    "Our distribution of delays, here at one stop is therefore not really normal but close enough for us to assume a normal distribution. We can add that taking more hours to compute the delays (2h-gaps,3h-gaps, etc.) would get us closer to a normal distribution, but a mean delay during a 3hour shift does not really mean anything : the delay at 2pm should not be the same, at a stop, than during peak hours around 5pm. We thus decided to do it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac82ac6-c4ea-4f62-9acd-4bade8a6af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%spark\n",
    "#delays_stats_df.repartition(1).write.option('header',True).csv(\"/user/rochepea/delays_stats_df.csv\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa461f9-9048-409b-805b-b3db7593abd9",
   "metadata": {},
   "source": [
    "## 3. A CSA-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7bc40-d2c6-4ce1-9570-816e3439bf6e",
   "metadata": {},
   "source": [
    "We reckon that the query to which our work is answering is the following : **What route from A to B is the fastest at least Q% of the time if I want to arrive at B before instant T ?**\n",
    "\n",
    "In order to take advantage of the data we were given, we opted to heavily base our algorithm on the Connection Scanning Algorithm (CSA) introduced by Dibbelt et al. in 2018. Unless some methods such as the A* or Dijkstra's algorithms, CSA is not network/graph based and only iterates on a timetable containing connections that we're interested in.\n",
    "\n",
    "Here, we consider a connection to be a vehicle (Bus, Train, Tram, Metro, etc.) that links two different stops without any halt. A connection is therefore characterized by 5 elements :\n",
    "- The trip to which the connection belongs ($c_{trip}$)\n",
    "- The connection's departure stop ($c_{dep\\_stop}$)\n",
    "- The connection's arrival stop ($c_{arr\\_stop}$)\n",
    "- The connection's departure time ($c_{dep\\_time}$)\n",
    "- The connection's arrival time ($c_{arr\\_time}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771bf96c-89c5-42de-acef-06adaa44369c",
   "metadata": {},
   "source": [
    "### 3.1 Introduction to the CSA : the Earliest Arrival problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0ab4c-f2d8-42fa-9ead-8c54b1805362",
   "metadata": {},
   "source": [
    "\n",
    "Let us introduce the basic implementation of CSA for the Earliest Arrival problem : We want to obtain the earliest arrival time $\\tau_{d}$ at a target stop $d$, given a source stop $s$ and a source departure time $\\tau_{s}$.\n",
    "\n",
    "The only preprocessing we need for the algorithm to work properly is to sort our connections timetable $C$ by **increasing order of departure time,** $c_{dep\\_time}$, as well as a table containing all the existing footpaths between our stops (the ones that are <500m away in our case).\n",
    "\n",
    "Two data structures (within the algorithm) are also needed to keep track of these operations :\n",
    "\n",
    "- The tentative arrival times for each of our stops, which is an array $T$.\n",
    "- The reachability flags for each trip (TRUE or FALSE values), stored in an array $R$. These flags indicates if the user has been able to hop on one of the connections in a particular trip.\n",
    "\n",
    "CSA then works by iterating on this sorted timetable of connections only once while performing simple operations on each connection, based on these data structures. \n",
    "Very quickly, each connection of interest (following some starting/stopping criteria) is tested for reachability and if it is indeed reachable, the tentative arrival times for each stops in walking distance of the arrival stop of the connection are improved if possible.\n",
    "\n",
    "A way more detailed and throughout explanation of the algorithm is provided in the short video explaining our project, but the pseudo-code explaining the earliest time CSA is shown just below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf397d0-8d17-4322-8164-1ace7a6ccd3b",
   "metadata": {},
   "source": [
    "<img src=\"../figs/EACSA.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d31289-ffd9-4d18-a770-03985f19661a",
   "metadata": {},
   "source": [
    "### 3.2 Adaptation of the earliest arrival CSA to build a journey planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c33f03-7b2f-4d40-8bd8-00e132d6058c",
   "metadata": {},
   "source": [
    "#### 3.2.1 In theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac68f4c-713e-4ae5-af7e-bcf1812b42b3",
   "metadata": {},
   "source": [
    "Choosing CSA as the base algorithm for the project left us with several challenges :\n",
    "- Besides the two stops, the earliest arrival CSA takes a departure time as an input, while in our case, the user will only give an arrival time at the destination stop. \n",
    "\n",
    "- This version of the algorithm is also made to only output the arrival time at destination. However, in our case, we would like to be able to reconstruct a route from departure stop to arrival stop as well.\n",
    "\n",
    "- The delays are not taken into account in the algorithm neither, while they are a very important part of the journey planning\n",
    "\n",
    "\n",
    "Our method thus answers these three big challenges and constructs a journey planner that that works with only an arrival time, the departure and arrival stops as well as the Q% the user enquires for. \n",
    "\n",
    "1. First, we decided to keep the CSA in the \"Earliest Arrival form\", meaning that our `updatedCSA` function runs with a departure time as a parameter. We brought modifications to the algorithm in order to be able to correctly reconstruct the route after finding the arrival time at the destination stop. \n",
    "\n",
    "    While updating the tentative arrival times, we don’t only store this value alone anymore, but a triple containing the latter with two other values : whether it was improved by a footpath or a connection, and the index of that specific footpath or connection. At the very end of the loop explained earlier, we then backtrack, from the latest stop, thanks to the stored indices, the connections or footpaths that allowed us to obtain this earliest arrival time at the destination stop, as shown on Figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47321195-8349-4e05-b60a-24ee371c124e",
   "metadata": {},
   "source": [
    "<img src=\"../figs/journey_reconstruction.png\" width=\"800\"/>\n",
    "\n",
    "_Figure 3._ Illustration of the journey reconstruction method we used. For each stop, the tentative arrival time is stored as well as the travel method ('connection' or 'footpath') and the index of the connection of footpath that allowed the improvement. Starting from the last stop, when the CSA algorithm is done running, we reconstruct the journey backwards by looking at which connexions allowed to obtain this earliest arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368d99c-9201-48f7-895d-0b47aa996160",
   "metadata": {},
   "source": [
    "2. Having a way to construct a route, we needed to circumvent the fact that the user inputs an arrival time and not a departure time, we decided to perform a first step where we apply the algorithm with the departure time being the same as the arrival time given by the user. Let’s say that the user wants to arrive at stop B no later than 9:30 : we then set our departure time to also be 9:30 at stop A.\n",
    "\n",
    "    Obviously, this won’t yield any valid arrival time that is below or equal 9:30 at stop B. We thus reduce this 9:30 departure time to 9:29 and see if any arrival time below or equal to 9:30 is found. This is done until we find a departure time that gives an arrival time, at stop B, which is below or equal to 9:30. This is our latest departure time, as the CSA won’t allow us to find any later departures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6af002-0e8d-4232-8b17-3736412c2841",
   "metadata": {},
   "source": [
    "3. Now that we have a valid departure time for our problem, we need to find several routes linking A to B as we remember that our algorithm only outputs a single route. We thus apply our algorithm to different departure times, spaced by 5 minutes, until an arbitrary time of 1 hour before the valid departure time found earlier. At each of these times, we would then find an optimal route linking A to B : we then re-run the algorithm by severing/deleting the connections present on this route. This way, we’re forcing our algorithm to consider other connections than the ones yielding the optimal route on each trip, which might also be the riskiest. \n",
    "\n",
    "    Let us take again the example just above and let us assume that the first step found a valid departure time of 9:20. We would then run the algorithm with departure times being 9:15, 9:10, 9:05, etc. For each of these times, if an optimal route is found, we run the algorithm as many times as the number of trip_ids in this optimal route, by thus suppressing it from our connections table. This allows to find other valid routes that link our departure stop to our arrival stop, without this trip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dbcc6-78ac-4b86-bba7-07631245a32a",
   "metadata": {},
   "source": [
    "4. The way in which we take the delays into account are explained in part 3.3.3 and in the video (Part of Mehdi Sellami)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb96b01-8c60-4d1b-906e-fadb9053dfd8",
   "metadata": {},
   "source": [
    "### 3.3 In practice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619a933-f964-4b4e-9a2d-21cf7b42fcb9",
   "metadata": {},
   "source": [
    "#### 3.3.1 Local data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b9f6d-94e6-4b94-8b89-3f8790b775a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the necessary dataframes\n",
    "connections = pd.read_csv('../data/connections.csv')\n",
    "footpaths = pd.read_csv('../data/footpaths.csv')\n",
    "transport_types = pd.read_csv('../data/transport_types.csv')\n",
    "stops_coordinates = pd.read_csv('../data/all_stops.csv').drop(['location_type','parent_station','distance_from_zur'],axis=1)\n",
    "delays_stats = pd.read_csv('../data/delays_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d99651-27d5-49c6-ba35-f5c57424ec9c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <strong>Information!</strong> The below cell runs some additional preprocessing on the dataframes loaded just above (takes ~30s). This preprocessing would have been better if done using PySpark, but we decided to do it here due to the complications we had with running PySpark sessions/operations in the last days of the project.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51558fa7-8e34-486b-994e-60c3411994bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the transport types.\n",
    "#We rearrange the different transport_types dataframe to only have to Bus, Tram, or Train transport types.\n",
    "rows_to_remove = transport_types['route_desc'].isin(['FUN', 'FAE', 'PB', 'BAT'])\n",
    "transport_types = transport_types[~rows_to_remove]\n",
    "modify_to_train = transport_types['route_desc'].isin(['S','IR','IC','RE',''])\n",
    "modify_to_tram = transport_types['route_desc'].isin(['T'])\n",
    "modify_to_bus = transport_types['route_desc'].isin(['B'])\n",
    "transport_types.loc[modify_to_train, 'route_desc'] = 'Train'\n",
    "transport_types.loc[modify_to_tram, 'route_desc'] = 'Tram'\n",
    "transport_types.loc[modify_to_bus, 'route_desc'] = 'Bus'\n",
    "\n",
    "\n",
    "#We remove the delays computed for Saturday or Sunday as we're not having any connections on those days in our timetable\n",
    "delays_to_remove = delays_stats['weekday'].isin(['Saturday','Sunday'])\n",
    "delays_stats = delays_stats[~delays_to_remove]\n",
    "\n",
    "#Building necessary structures for the forward CSA : footpaths and connections timetables. We basically only keep the\n",
    "#connections with valid transport types (if not filtered out earlier), and filter the footpaths based on the\n",
    "#stops through which actual connections stop.\n",
    "unique_trip_ids = transport_types['trip_id'].unique()\n",
    "mask = connections['trip_id'].isin(unique_trip_ids)\n",
    "selected_connections = connections[mask]\n",
    "\n",
    "unique_stops_list = np.unique(selected_connections[['departure_stop','arrival_stop']].values)\n",
    "unique_trips_list = selected_connections.trip_id.unique()\n",
    "footpaths = footpaths[footpaths['first_stop_id'].isin(unique_stops_list) &\n",
    "                                footpaths['second_stop_id'].isin(unique_stops_list)]\n",
    "\n",
    "#Getting our footpaths in a more usable manner for the CSA algorithm\n",
    "all_footpaths = [list(row) for idx,row in footpaths.iterrows()]\n",
    "\n",
    "#Sort the timetable and put the time strings into Timestamps\n",
    "selected_connections = selected_connections.sort_values('departure_time')\n",
    "selected_connections['departure_time'] = pd.to_datetime(selected_connections['departure_time'])\n",
    "selected_connections['arrival_time'] = pd.to_datetime(selected_connections['arrival_time'])\n",
    "\n",
    "#Getting our connections in a more usable manner for the CSA algorithm\n",
    "all_connections = [list(row) for idx,row in selected_connections.iterrows()]\n",
    "\n",
    "#One final filter of the all_stops and delays_stats dataframes to only keep the stop_ids we're interested in\n",
    "stops_coordinates = stops_coordinates[stops_coordinates['stop_id'].isin(unique_stops_list)]\n",
    "delays_stats = delays_stats[delays_stats['stop_id'].isin(unique_stops_list)]\n",
    "\n",
    "#Build a dictionnary for transport types : (key = 'trip_id' & value = transport type) \n",
    "#and meta-information about our stops : (key = 'trip_id', value = [stop_name, lat, lon]\n",
    "ttypes_dict = transport_types.set_index(transport_types.columns[0]).to_dict()[transport_types.columns[1]]\n",
    "stops_info_dict = stops_coordinates.set_index('stop_id').\\\n",
    "    apply(lambda row: [row['stop_name'], row['stop_lat'], row['stop_lon']], axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa52401-69f7-4fe0-b973-0492c4c22f4d",
   "metadata": {},
   "source": [
    "#### 3.3.2 Updated CSA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b7057-f0a0-402a-abcf-97ee274667f6",
   "metadata": {},
   "source": [
    "The following function performs a binary search : it returns the index of the first connection departing no later than a certain departure time. It is used in the core `UpdatedCSA` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1d142-951f-4bd3-b835-e9a00169f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_connection(connections,low,high,start_time):\n",
    "\n",
    "    if high >= low:\n",
    "        mid = (high + low) // 2\n",
    "\n",
    "        if connections[mid][2] == start_time:\n",
    "            return mid\n",
    "\n",
    "        # If element is smaller than mid, then it can only\n",
    "        # be present in left subarray\n",
    "        elif connections[mid][2] > start_time:\n",
    "            return find_first_connection(connections, low, mid - 1, start_time)\n",
    "\n",
    "        # Else the element can only be present in right subarray\n",
    "        else:\n",
    "            return find_first_connection(connections, mid + 1, high, start_time)\n",
    "\n",
    "    else:\n",
    "        # Element is not present in the array\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfff997-aa60-4fa3-9b23-0c3abdeabf9e",
   "metadata": {},
   "source": [
    "The `UpdatedCSA` function is the core function of our algorithm. It follows the pseudo code of Figure 2 to retrieve the earliest arrival time at the arrival stop, and it follows the logic explained in Figure 3 to retrieve an optimal route and to reconstruct it. We also set a `reconstructing_journey` boolean depending on if we want to reconstruct a journey or not. For instance, to find the latest departure time, we use this function but we don't want to even try and reconstruct a route : the boolean will thus be set to 0. Otherwise, to reconstruct routes, we set it to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b95bf8-0d69-4294-825c-476b97638c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdatedCSA(source,destination,source_time,connections,footpaths,deleted_trips,reconstructing_journey) :\n",
    "    \"\"\".\n",
    "    Implementation of an updated CSA version for the earliest arrival problem.\n",
    "    \n",
    "    Parameters:\n",
    "    source (string) : The source stop of the journey we aim to build.\n",
    "    destination (string) : The destination stop of the journey we aim to build\n",
    "    source_time (datetime) : The time at which the journey starts at our source stop\n",
    "    connections (List) : Timetable containing all the connections in our preprocessed network\n",
    "    footpaths (List) : Table containing all the valid footpaths between the stops present in our network\n",
    "    deleted_trips (list) : List of trips that we don't want to consider in the CSA algorithm \n",
    "    reconstructing_journey (boolean) : Set to True if we want to reconstruct the route in addition to the arrival time\n",
    "    \n",
    "    Returns:\n",
    "     \n",
    "    The earliest arrival time at the destination and the journey linking the source to the destination.\n",
    "    \"\"\"\n",
    "    #First, the T array containing the tentative arrival times for each stops :\n",
    "    T = {}\n",
    "    for stop in unique_stops_list : \n",
    "        T[stop] = [0,None,None]\n",
    "    #Then the reachability flag for each trip_id :\n",
    "    R = {}\n",
    "    for trip in unique_trips_list:\n",
    "        R[trip] = 0\n",
    "\n",
    "    today = datetime.datetime.now().date()\n",
    "    transfer_time = datetime.timedelta(minutes = 2)\n",
    "    #Initializing the T and S dictionnaries\n",
    "    for stop_id in T :\n",
    "        T[stop_id][0] = datetime.datetime.combine(today,datetime.time(hour=23, minute=59, second = 59))\n",
    "    for trip in R :\n",
    "        R[trip] = 0\n",
    "    \n",
    "    T[source][0] = source_time\n",
    "    #For all the stops reachable by foot from the source, update the tentative arrival times\n",
    "    for foot_idx,footpath in enumerate(footpaths) :\n",
    "        if footpath[0] == source :\n",
    "            T[footpath[2]] = [source_time + datetime.timedelta(minutes = footpath[5]),'footpath', foot_idx]\n",
    "    \n",
    "    #Find the index of the first connection c_0\n",
    "    low = 0\n",
    "    high = len(connections) - 1\n",
    "    starting_idx = find_first_connection(connections,low,high,source_time)\n",
    "    \n",
    "    #Starting from c_0\n",
    "    for idx,connection in enumerate(connections[starting_idx:]) :\n",
    "        idx = idx + starting_idx\n",
    "        #Check if the current connection is not part of deleted_trips,\n",
    "        if not (connection[0] in deleted_trips) :\n",
    "            #Check if the departure time of the current connection is >= the tentative time of the destination stop,\n",
    "            if T[destination][0] <= connection[2] :\n",
    "                break\n",
    "            #Check if the connection is reachable,\n",
    "            if T[connection[1]][0] < (connection[2] - transfer_time) or R[connection[0]] :\n",
    "                R[connection[0]] = 1\n",
    "                #Check if it improves the tentative arrival time of the arrival stop of the current connection\n",
    "                if connection[4] < T[connection[3]][0] :\n",
    "                    T[connection[3]] = [connection[4],'connection',idx]\n",
    "                    #We try to improve all the tentative arrival times for the stops reachable by foot from the current connection's \n",
    "                    #arrival stop\n",
    "                    for foot_idx,footpath in enumerate(footpaths) :\n",
    "                        if footpath[0] == connection[3] :\n",
    "                            if T[footpath[2]][0] > connection[4] + datetime.timedelta(minutes = footpath[5]):\n",
    "                                    T[footpath[2]] = [connection[4] + datetime.timedelta(minutes = footpath[5]),'footpath',foot_idx]\n",
    "     \n",
    "    if reconstructing_journey :\n",
    "        journey = []\n",
    "        current_stop = destination\n",
    "        while current_stop != source :\n",
    "            step = []\n",
    "            current_stop_info = T[current_stop]\n",
    "            curr_arr_time,step_type,idx = current_stop_info[0],current_stop_info[1],current_stop_info[2]\n",
    "            if step_type == 'footpath' :\n",
    "                step = all_footpaths[idx]\n",
    "                journey.append(['Walking',step[0],curr_arr_time - datetime.timedelta(minutes =step[5]),step[2],curr_arr_time,'Walking'])\n",
    "                current_stop = step[0]\n",
    "            if step_type == 'connection' :\n",
    "                step = connections[idx].copy()\n",
    "                transport_type = ttypes_dict[step[0]]\n",
    "                step.append(transport_type)\n",
    "                journey.append(step)\n",
    "                current_stop = step[1]\n",
    "            if step_type == None :\n",
    "                return(T[destination][0],[])\n",
    "          \n",
    "        return(T[destination][0],journey) \n",
    "    \n",
    "    else :\n",
    "        return(T[destination][0],[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320112b-03c8-4b75-82ab-ee93f4f4352e",
   "metadata": {},
   "source": [
    "This function is used to find the first and thus latest departure time based on a given arrival time at destination. This will be the core function when trying to valid departure time when provided with a query from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86407bf7-ff4e-4912-9320-2ec036b629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DepartureTimeFinder(source,destination,arrival_time,connections,footpaths) :\n",
    "    \"\"\"\n",
    "    Find a valid latest departure time given the user's desired arrival time at destination.\n",
    "    \n",
    "    Parameters:\n",
    "    source (string) : The source stop of the journey \n",
    "    destination (string) : The final arrival stop of the journey\n",
    "    arrival_time (datetime) : Latest arrival time of the journey (queried by the user)\n",
    "    connections (List) : Timetable containing all the connections in our preprocessed network\n",
    "    footpaths (List) : Table containing all the valid footpaths between the stops present in our network\n",
    "    \n",
    "    Returns: \n",
    "    The first valid departure time found by the CSA algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Defining a 3hours time interval with a 1min frequency before arrival time to find the departure time\n",
    "    departure_times= pd.date_range(start=arrival_time - datetime.timedelta(hours = 3), end=arrival_time, freq='1min').tolist()\n",
    "    departure_times.reverse()\n",
    "    \n",
    "    best_departure_time = None\n",
    "    #For each of our tentative departure times, we check if we can find an arrival time which is < arrival_time, If it is, we select it\n",
    "    #and end the loop.\n",
    "    for curr_dep_time in departure_times :\n",
    "        best_found_arrival = UpdatedCSA(source,destination,curr_dep_time,all_connections,all_footpaths,[],0)[0]\n",
    "        if best_found_arrival <= arrival_time :\n",
    "            best_departure_time = curr_dep_time\n",
    "            return(pd.to_datetime(best_departure_time.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "        \n",
    "    return(best_departure_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c707db-4248-4c41-af40-cc3a85c425b0",
   "metadata": {},
   "source": [
    "`RoutesLister` reconstruct a list of routes for a certain departure time of travel. A first route is reconstructed (the most optimal one) and all the trip_ids of this route are registered. One trip_id at a time, all connections that are part of this trip are virtually removed from the connections timetable to find other routes, if possible, linking A to B for this particular departure time. We also double check that the arrival time of the connection is indeed smaller than the query of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea850c-15aa-4ebb-814b-24e61f991a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoutesLister(source,destination,departure_time,arrival_time,connections,footpaths) :\n",
    "    \"\"\"\n",
    "    Find routes linking the source to destination.\n",
    "    \n",
    "    Parameters:\n",
    "    source (string) : The source stop of the journey \n",
    "    destination (string) : The final arrival stop of the journey\n",
    "    departure_time (datetime) : Departure time of the journey\n",
    "    arrival_time(datetime) : Arrival time of the journey\n",
    "    connections (List) : Timetable containing all the connections in our preprocessed network\n",
    "    footpaths (List) : Table containing all the valid footpaths between the stops present in our network\n",
    "    \n",
    "    Returns: \n",
    "    A list of routes linking source to destination.\n",
    "    \"\"\"\n",
    "    routes = []\n",
    "    \n",
    "    #Find the first route linking source to destination when leaving at source_time\n",
    "    first_arrival_time, first_route = UpdatedCSA(source,destination,departure_time,all_connections,all_footpaths,[],1)\n",
    "    routes.append(first_route)\n",
    "    \n",
    "    #Retrieve all the trip_ids present in this specific route\n",
    "    first_trip_ids = list(set(connection[0] for connection in first_route if connection[0] != 'Walking'))\n",
    "    \n",
    "    #For each of these trip_ids, try to find a route that uses other connections. If no route without a certain connection,\n",
    "    #we don't append it\n",
    "    for trip_id in first_trip_ids :\n",
    "        new_arrival_time,new_route = UpdatedCSA(source,destination,departure_time,all_connections,all_footpaths,[trip_id],1)\n",
    "        if (new_arrival_time <= arrival_time) & (new_route != None) :\n",
    "            routes.append(new_route)\n",
    "            \n",
    "    return(routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244d260-86b7-48a7-8995-a46e9c01f6bd",
   "metadata": {},
   "source": [
    "This last function basically uses the `RoutesLister` function on different departure times, to reconstruct a list of routes that we can then filter for the Q value and order by number of transfers, stops, etc. It therefore encapsulates all the other functions previously defined in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f70133-c447-4277-b4b1-3a8984f00086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffTimesRouteLister(source,destination,arrival_time,connections,footpaths) :\n",
    "    \"\"\"\n",
    "    Find routes linking the source to destination for different departure times at source.\n",
    "    \n",
    "    Parameters:\n",
    "    source (string) : The source stop of the journey (queried by the user)\n",
    "    destination (string) : The final arrival stop of the journey (queried by the user)\n",
    "    arrival_time(datetime) : Arrival time of the journey (queried by the user)\n",
    "    connections (List) : Timetable containing all the connections in our preprocessed network\n",
    "    footpaths (List) : Table containing all the valid footpaths between the stops present in our network\n",
    "    \n",
    "    Returns: \n",
    "    A dictionnary of routes, where the key is a departure time and the value is a list of routes linking source to destination, for this \n",
    "    departure time\n",
    "    \"\"\"\n",
    "    routes_dic = {}\n",
    "    \n",
    "    #We first find the first valid departure time for the arrival time wanted by the user\n",
    "    first_departure_time = DepartureTimeFinder(source,destination,arrival_time,connections,footpaths)\n",
    "    if first_departure_time == None :\n",
    "        return(TypeError('No suitable departure time was found for a trip from {} to {}, arriving no later than {}'.format(source,destination,arrival_time)))\n",
    "    \n",
    "    departure_times= pd.date_range(start=first_departure_time - datetime.timedelta(hours = 1), end=first_departure_time, freq='5min').tolist()\n",
    "    departure_times.reverse()\n",
    "    \n",
    "    for new_departure_time in departure_times :\n",
    "        routes_dic[new_departure_time] = RoutesLister(source,destination,new_departure_time,arrival_time,connections,footpaths)\n",
    "        \n",
    "    return(routes_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddd288-3930-4902-beb1-04fd2349f396",
   "metadata": {},
   "source": [
    "#### 3.3.3 Delays & Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c5bca-fea0-4e15-8a75-98db39e428d6",
   "metadata": {},
   "source": [
    "The main function in this part is add_q_to_routes, which adds a Q-value to each route in a given dictionary of routes. The Q-value represents the probability of a route being feasible with potential delays at least Q% of the time, considering the desired arrival time and the confidence tolerance.\n",
    "\n",
    "The algorithm uses a delay dataset,  which contains information about the delays for each stop_id and transport type,hour of arrival and weekday. It calculates the Q-value for each route by considering the delays and arrival time. The Q-value is then added to the route.\n",
    "\n",
    "The route planner includes several utility functions:\n",
    "\n",
    "reduce_route: Reduces a route by removing consecutive stops with the same trip_id. This is due to the assumption that the last stop of a trip encapsulates the delays of the previous stop on the same trip.\n",
    "\n",
    "get_delay_stats: Retrieves delay statistics for a given stop ID, transport type, arrival time, weekday, and the delay dataset. If specific delay information is not available, it uses the mean and  standard deviation of the entire dataset.\n",
    "\n",
    "get_time_diff: Calculates the time difference in minutes between two timestamps.\n",
    "\n",
    "get_prob: Calculates the probability given the time left, mean, and standard deviationusing a normal distribution.\n",
    "\n",
    "get_q_value: Calculates the Q-value for a given route, arrival time, and delay dataset. It considers the delays for each stop along the route and computes the cumulative Q-value.\n",
    "\n",
    "The route planner thus functions in the follwing manner :\n",
    "Provide a dictionary of routes containing the possible routes between departure \n",
    "and arrival stops.\n",
    "Specify the arrival time and the desired Q-value threshold (Q%) as inputs\n",
    " to the add_q_to_routes function.\n",
    "Pass the delays dataset and the queried weekday as arguments to the add_q_to_routes\n",
    " function.\n",
    "The function will return a new dictionary of routes with the Q-values\n",
    " added to each route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d306f23-6a34-45e6-9dd3-ed9fd18679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the mean and std of all the delays\n",
    "mean_value_delays = 1.227\n",
    "std_value_delays = 1.428\n",
    "def add_q_to_routes(all_routes_dict,arrival_time,delays,desired_Q,queried_weekday):\n",
    "    \"\"\"\n",
    "    Adds a Q-value to each route in the given dictionary of routes.\n",
    "\n",
    "    Args:\n",
    "        all_routes_dict (dict): A dictionary containing routes.\n",
    "        arrival_time (datetime): The arrival time.\n",
    "        delays (pd.DataFrame): A DataFrame containing delay information.\n",
    "        desired_Q (float): The desired Q-value threshold.\n",
    "        queried_weekday (string): The weekday of the trip\n",
    "    Returns:\n",
    "        dict: A new dictionary with Q-values added to the routes.\n",
    "    \"\"\"\n",
    "        \n",
    "    new_routes_list = []\n",
    "    for key in all_routes_dict:\n",
    "        routes = all_routes_dict[key]\n",
    "        for index, route in enumerate(routes):\n",
    "            q_value = get_q_value(route,arrival_time,queried_weekday,delays)\n",
    "            if q_value>= desired_Q:\n",
    "                new_route = []\n",
    "                for x in list(reversed(route)):\n",
    "                    x.append(q_value)  \n",
    "                    new_route.append(x)  \n",
    "                new_routes_list.append(new_route)\n",
    "\n",
    "    return new_routes_list\n",
    "\n",
    "\n",
    "def reduce_route(route):\n",
    "    \"\"\"\n",
    "    Reduces the given route by removing consecutive stops with the same stop_id.\n",
    "\n",
    "    Args:\n",
    "        route (list of list): A list of lists containing the information about each stop\n",
    "\n",
    "    Returns:\n",
    "        list of list: A new route with consecutive stops having the same trip_id removed.\n",
    "    \"\"\"\n",
    "        \n",
    "    new_route = []\n",
    "    for i in range(len(route)-1):\n",
    "        if route[i][0] != route[i+1][0]:\n",
    "            new_route.append(route[i])\n",
    "    new_route.append(route[-1])\n",
    "    \n",
    "    return new_route \n",
    "\n",
    "def get_delay_stats(stop_id,transport_type,arr_time,weekday,delays):\n",
    "    \"\"\"\n",
    "    Retrieves delay statistics for the given stop_id, transport_type, arrival time, weekday, and delays DataFrame.\n",
    "\n",
    "    Args:\n",
    "        stop_id (str): The stop ID.\n",
    "        transport_type (str): The transport type.\n",
    "        arr_time (timestamp): arrival time.\n",
    "        weekday (str): The weekday.\n",
    "        delays (pd.DataFrame): A DataFrame containing delay information.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the mean delay and standard deviation.\n",
    "    \"\"\"\n",
    "    #for some stop_ids we don't have a delay, we use the weighted sum and std of all the dataset\n",
    "    \n",
    "    datetime_obj = pd.to_datetime(arr_time)\n",
    "    hour = datetime_obj.hour\n",
    "    if ':' in stop_id:\n",
    "        #these values were calculated at the end of 2.4\n",
    "        return mean_value_delays,std_value_delays\n",
    "    row = delays[(delays['stop_id'] == int(stop_id)) &\n",
    "                  (delays['transport_type'] == transport_type) &\n",
    "                  (delays['arrival_hour'] == hour) &\n",
    "                  (delays['weekday'] == weekday)]\n",
    "   \n",
    "    is_empty = row.empty\n",
    "    if is_empty:\n",
    "        #these values were calculated at the end of 2.4\n",
    "        return mean_value_delays,std_value_delays\n",
    "    mu = row['mean_delay'].item()\n",
    "    std = row['stddev_delay'].item()\n",
    "    return mu,std\n",
    "\n",
    "def get_time_diff(timestamp1,timestamp2):\n",
    "    \"\"\"\n",
    "    Calculates the time difference in minutes between two timestamps.\n",
    "\n",
    "    Args:\n",
    "        timestamp1 (pd.Timestamp): The first timestamp.\n",
    "        timestamp2 (pd.Timestamp): The second timestamp.\n",
    "\n",
    "    Returns:\n",
    "        float: The time difference in minutes.\n",
    "    \"\"\"\n",
    "    timestamp1 = timestamp1.to_pydatetime()\n",
    "    timestamp2 = timestamp2.to_pydatetime()\n",
    "        \n",
    "    time_difference = timestamp2 - timestamp1\n",
    "    return time_difference.total_seconds()/60\n",
    "        \n",
    "def get_prob(time_left,mu,std):\n",
    "    \"\"\"\n",
    "    Calculates the probability given the time left, mean, and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        time_left (float): The time left.\n",
    "        mu (float): The mean value of the delays.\n",
    "        std (float): The standard deviation of the delays.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated probability.\n",
    "    \"\"\"\n",
    "    probability = norm.cdf(time_left, mu, std)\n",
    "\n",
    "    return probability\n",
    "\n",
    "def get_q_value(route,arrival_time,queried_weekday,delays):\n",
    "    \"\"\"\n",
    "    Calculates the Q-value for the given route, arrival time, and delays DataFrame.\n",
    "\n",
    "    Args:\n",
    "        route (list of list): A list of lists containing the information about each stop\n",
    "        arrival_time (datetime): The arrival time.\n",
    "        queried_weekday(str): The weekday of the trip\n",
    "        delays (pd.DataFrame): A DataFrame containing delay information.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated Q-value.\n",
    "    \"\"\"\n",
    "    reduced_route = reduce_route(route)\n",
    "    q_value = 1\n",
    "    walk_left_over = 0\n",
    "    walked = False\n",
    "    offset = 0\n",
    "    stop_id,transport_type,arr_time,weekday,dep_time = 0,0,0,0,0\n",
    "    if reduced_route[-1][0] == 'Walking':\n",
    "        offset = 1\n",
    "    for i in range(len(reduced_route)-1-offset,0,-1):\n",
    "        if reduced_route[i-1][0] == 'Walking':\n",
    "            walked = True\n",
    "            stop_id = reduced_route[i][3]\n",
    "            transport_type = reduced_route[i][5]\n",
    "            arr_time = reduced_route[i][4]\n",
    "            dep_time = reduced_route[i-1][2]\n",
    "            weekday = queried_weekday\n",
    "            walk_left_over = get_time_diff(arr_time,dep_time)\n",
    "            continue\n",
    "        if not(walked):\n",
    "            stop_id = reduced_route[i][3]\n",
    "            transport_type = reduced_route[i][5]\n",
    "            arr_time = reduced_route[i][4]\n",
    "            dep_time = reduced_route[i-1][2]\n",
    "            weekday = queried_weekday\n",
    "        mu,std = get_delay_stats(stop_id,transport_type,arr_time,weekday,delays)\n",
    "       \n",
    "        arr_time = reduced_route[i][4]\n",
    "        dep_time = reduced_route[i-1][2]\n",
    "        time_diff = get_time_diff(arr_time,dep_time) + walk_left_over\n",
    "        proba = get_prob(time_diff,mu,std)\n",
    "        q_value *=proba\n",
    "        walk_left_over = 0\n",
    "        walked = False\n",
    "        \n",
    "    if reduced_route[0][0]=='Walking':\n",
    "        mu,std = get_delay_stats(stop_id,transport_type,arr_time,weekday,delays)\n",
    "        \n",
    "        arr_time = reduced_route[0][4]\n",
    "        time_diff = get_time_diff(arr_time,arrival_time)+walk_left_over\n",
    "        proba = get_prob(time_diff,mu,std)\n",
    "        q_value *=proba\n",
    "        return q_value\n",
    "    stop_id = reduced_route[0][3]\n",
    "    transport_type = reduced_route[0][5]\n",
    "    arr_time = reduced_route[0][4]\n",
    "    weekday = queried_weekday\n",
    "    time_diff = get_time_diff(arr_time,arrival_time)\n",
    "    mu,std = get_delay_stats(stop_id,transport_type,arr_time,weekday,delays)\n",
    "    proba = get_prob(time_diff,mu,std)\n",
    "   \n",
    "    q_value *=proba\n",
    "    return q_value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d8b70-f84e-460a-8cb1-2d9671e32100",
   "metadata": {},
   "source": [
    "#### 4. Visualization & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a1ef9-1b66-46fa-a788-0a7091ea3a39",
   "metadata": {},
   "source": [
    "We're now ready to first visualize and then run some validation tests on our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbdc61-b2a0-4967-a40c-76aece3e4d0c",
   "metadata": {},
   "source": [
    "#### 4.1 Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acd75b-d6d4-48ae-afc4-c2430a2d6608",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Important!</strong> Please read carefully the few following lines to understand how to use our visualization interface.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f2b67-53f3-484b-9c4c-b497dfdf0a0c",
   "metadata": {},
   "source": [
    "To be able to visualize the results in a user-friendly manner we've created the two code cells below :\n",
    "\n",
    "- The first cell, **when ran**, is going to output widgets from which the user will be able to select the different parameters of the trip. They include both departure and arrival stops, the arrival time (hour + minute, the weekday during which we want to make the trip and the Q value to query. \n",
    "\n",
    "    \n",
    "    When the user is done choosing these values, clicking on the **'RUN'** button will fetch a list of routes taking all the parameters into account. A text will then appear, indicating the number of routes that have been found for this list of parameters. The visualization itself takes place in the next code cell.\n",
    "    \n",
    "    If needed, the user can also reset all the widgets to some default values by pressing the **'RESET'** button."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91af2bc-234a-4c9d-b90e-69fe10884c0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ WARNING! The following markdown cell explains what should normally be happening when running the second cell. \n",
    "    To visualize our results on a map in a nice manner, we used the folium package. Unfortunately, with Renku, even with trying to trust the current notebook with our best efforts, it won't allow us to show the map. The routes results (connections, confidence value) are thus available on the logs of the notebook and the current route shown is displayed in 'map.html'.  We deeply apologize for the inconvenience.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef9790-a37a-412c-af82-022857de02be",
   "metadata": {},
   "source": [
    "- The second cell will allow the user to visualize the actual result of the query. A button \"Show route\" can be clicked and a dropdown menue shows a list of routes, ordered by latest departure times, transfers, walking distances and q values. When clicking the button, a map is displayed with some text containing the important information about the route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a7511-e0b5-4ab2-b6f7-518fed82c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "#Set the usable \n",
    "choosable_stops = set([stop[0] for stop in stops_info_dict.values()])\n",
    "choices = sorted(choosable_stops)\n",
    "\n",
    "Q_choice=widgets.FloatSlider(\n",
    "    value=0.95,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")\n",
    "\n",
    "start_stop=widgets.Dropdown(\n",
    "    options=choices,\n",
    "    value='Zürich, Klosbach'\n",
    ")\n",
    "\n",
    "end_stop=widgets.Dropdown(\n",
    "    options=choices,\n",
    "    value = 'Zürich, ETH/Universitätsspital'\n",
    ")\n",
    "\n",
    "day=widgets.Dropdown(\n",
    "    description='Pick a Day',\n",
    "    options = ['Monday','Tuesday','Wednesday','Thursday','Friday'],\n",
    "    value = 'Wednesday'\n",
    ")\n",
    "\n",
    "start_hour=widgets.Dropdown(\n",
    "    options=range(7,21),\n",
    "    description='Arrival Hour:',\n",
    "    value = 10,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "start_minute=widgets.Dropdown(\n",
    "    options=range(0,60),\n",
    "    description='Arrival Min.:',\n",
    "    value = 30,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "#initalize button\n",
    "first_button = widgets.Button(\n",
    "    description='RUN',\n",
    "    button_style='info',\n",
    "    tooltip='Query info'\n",
    ")\n",
    "\n",
    "result_label = widgets.Label()  # Label to display the message\n",
    "\n",
    "# Variable to store the result\n",
    "routes_found = None\n",
    "\n",
    "def on_query_clicked(f_b) :\n",
    "    \n",
    "    Q_value = Q_choice.value\n",
    "    user_start_stop = start_stop.value\n",
    "    user_end_stop = end_stop.value\n",
    "    user_day = day.value\n",
    "    user_start_hour = start_hour.value\n",
    "    user_start_minute = start_minute.value\n",
    "    \n",
    "    unique_routes= []\n",
    "    \n",
    "    arrival_time=pd.to_datetime(\"%02d:%02d:00\"%(user_start_hour,user_start_minute))\n",
    "    \n",
    "    start_id = [stop_id for stop_id, stop_info in stops_info_dict.items() if stop_info[0] == user_start_stop][0]\n",
    "    end_id = [stop_id for stop_id, stop_info in stops_info_dict.items() if stop_info[0] == user_end_stop][0]\n",
    "    \n",
    "    print(start_id,end_id,arrival_time,Q_value)\n",
    "    final_routes_dic = DiffTimesRouteLister(start_id,end_id,arrival_time,connections,footpaths)\n",
    "    if not isinstance(final_routes_dic,dict) :\n",
    "            unique_routes = []\n",
    "            result_label.value = 'No Routes have been found, please try again.'\n",
    "            \n",
    "    else :   \n",
    "            routes_list = add_q_to_routes(final_routes_dic,arrival_time,delays_stats,Q_value,user_day)\n",
    "    \n",
    "            if not isinstance(routes_list,list) or len(routes_list) == 0 :\n",
    "                unique_routes = []\n",
    "                routes_nb = len(unique_routes)\n",
    "                result_label.value = 'No Routes have been found, please try again.'\n",
    "    \n",
    "            else :\n",
    "                unique_tuples = set(tuple(tuple(connection) for connection in route) for route in routes_list)\n",
    "                unique_routes = [list(route) for route in unique_tuples]\n",
    "                routes_nb = len(unique_routes)\n",
    "                result_label.value = '{} Route(s) have been found! Please run the next cell to display them.'.format(routes_nb)\n",
    "    \n",
    "    \n",
    "    # Store the result in the variable\n",
    "    global final_routes\n",
    "    final_routes = unique_routes\n",
    "    \n",
    "    \n",
    "def reset_query(b):\n",
    "    # Reset the widget values\n",
    "    Q_choice.value = 0.95\n",
    "    start_stop.value = 'Zürich, Klosbach'\n",
    "    end_stop.value = 'Zürich, ETH/Universitätsspital'\n",
    "    day.value = 'Wednesday'\n",
    "    start_hour.value = 10\n",
    "    start_minute.value = 30\n",
    "    \n",
    "    # Reset the result variable and message\n",
    "    global final_routes\n",
    "    final_routes = None\n",
    "    result_label.value = \"\"\n",
    "    \n",
    "first_button.on_click(on_query_clicked)\n",
    "reset_button = widgets.Button(description='Reset')  # Reset button\n",
    "reset_button.on_click(reset_query)\n",
    "\n",
    "widget_by_row =[widgets.HBox([widgets.Label(\"Min Confidence Level:\"), Q_choice]),\n",
    "                widgets.HBox([widgets.Label(\"Starting station:\"), start_stop]),\n",
    "                widgets.\n",
    "                HBox([widgets.Label(\"Ending station:\"), end_stop]),\n",
    "                day,\n",
    "                widgets.HBox([start_hour,start_minute])]\n",
    "\n",
    "all_widget_in_one=widgets.VBox(widget_by_row)\n",
    "display(all_widget_in_one,first_button,result_label,output,reset_button)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a9c32-7a11-40dc-b2b8-87ca41dd2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "def sort_key(route):\n",
    "    departure_time = route[0][2].to_pydatetime()\n",
    "    walking_time = sum((trip[4].to_pydatetime() - trip[2].to_pydatetime()).total_seconds() for trip in route if trip[5] == 'Walking')\n",
    "    num_stops = len(route)\n",
    "    return (-departure_time.timestamp(), walking_time, num_stops)\n",
    "\n",
    "new_final_routes = sorted(final_routes, key=sort_key)\n",
    "routes = new_final_routes\n",
    "tooltip = None\n",
    "\n",
    "# Create a function to generate the tooltip for a stop position\n",
    "def get_stop_tooltip(trip_id, stop_id, dep_time, arr_time):\n",
    "    tooltip = f'Stop Name: {stop_id}<br>'\n",
    "    tooltip += f'Arrival Time at the stop: {arr_time}<br>'\n",
    "    tooltip += f'Departure Time from the stop : {dep_time}<br>'\n",
    "    tooltip += f'With trip ID: {trip_id}<br>'\n",
    "    return tooltip\n",
    "\n",
    "\n",
    "# Create a function to generate the tooltip for an edge (mode)\n",
    "def get_edge_tooltip(mode):\n",
    "    tooltip = f'Mode: {mode}<br>'\n",
    "    return tooltip\n",
    " \n",
    "\n",
    "def on_button_clicked(b):\n",
    "    \n",
    "    selected_route = dropdown.value - 1\n",
    "    clear_output()\n",
    "   \n",
    "    departure_stop = routes[selected_route][0][1]\n",
    "    print(departure_stop)\n",
    "    map_route = folium.Map(location=[stops_info_dict[departure_stop][1],stops_info_dict[departure_stop][2]], zoom_start=13)\n",
    "    \n",
    "    # Create markers for each stop position in the selected route\n",
    "    # Special case for the departure stop of the trip\n",
    "    first_trip, dep_stop, journey_dep_time, sec_stop, arr_time_sec_stop, ttype, conf = routes[selected_route][0]\n",
    "    first_stop_name, first_stop_lat, first_stop_lon = stops_info_dict[dep_stop][0], stops_info_dict[dep_stop][1], stops_info_dict[dep_stop][2]\n",
    "    first_tooltip = get_stop_tooltip(first_trip,first_stop_name,journey_dep_time.strftime(\"%H:%M:%S\"),'-')\n",
    "    folium.Marker(\n",
    "                location=[first_stop_lat, first_stop_lon],\n",
    "                tooltip=first_tooltip,\n",
    "                icon=folium.Icon(color=\"blue\")\n",
    "            ).add_to(map_route)\n",
    "        \n",
    "    for idx, position in enumerate(routes[selected_route][1:-1]):\n",
    "            trip_id, dep_stop, dep_time, arr_stop, arr_time, ttype, conf = position\n",
    "            prev_arr_time = routes[selected_route][idx][4]\n",
    "            stop_name, stop_lat, stop_lon = stops_info_dict[dep_stop][0], stops_info_dict[dep_stop][1], stops_info_dict[dep_stop][2]\n",
    "            tooltip = get_stop_tooltip(trip_id, stop_name, dep_time.strftime(\"%H:%M:%S\"), prev_arr_time.strftime(\"%H:%M:%S\"))\n",
    "            folium.Marker(\n",
    "                location=[stop_lat, stop_lon],\n",
    "                tooltip=tooltip,\n",
    "                icon=folium.Icon(color=\"blue\")\n",
    "            ).add_to(map_route)\n",
    "            \n",
    "    last_trip, last_dep_stop, last_dep_time, final_stop, journey_arr_time, ttype, conf = routes[selected_route][-1]\n",
    "    last_stop_name, last_stop_lat, last_stop_lon = stops_info_dict[final_stop][0], stops_info_dict[final_stop][1], stops_info_dict[final_stop][2]\n",
    "    last_tooltip = get_stop_tooltip('-',last_stop_name,'-',journey_arr_time.strftime(\"%H:%M:%S\"))\n",
    "    folium.Marker(\n",
    "                location=[last_stop_lat, last_stop_lon],\n",
    "                tooltip=last_tooltip,\n",
    "                icon=folium.Icon(color=\"blue\")\n",
    "            ).add_to(map_route)\n",
    "    \n",
    "        # Create polylines to connect consecutive stop positions in the selected route\n",
    "    for i in range(len(routes[selected_route])):\n",
    "            first_stop = routes[selected_route][i][1]\n",
    "            second_stop = routes[selected_route][i][3]\n",
    "            lng1,lat1 = stops_info_dict[first_stop][2], stops_info_dict[first_stop][1]\n",
    "            lng2,lat2 = stops_info_dict[second_stop][2], stops_info_dict[second_stop][1]\n",
    "            mode = routes[selected_route][i][5]\n",
    "            \n",
    "            polyline = folium.PolyLine(\n",
    "                locations=[(lat1, lng1), (lat2, lng2)],\n",
    "                color=\"red\",\n",
    "                weight=2.5,\n",
    "                opacity=1.0,\n",
    "                tooltip=get_edge_tooltip(mode)\n",
    "            )\n",
    "            map_route.add_child(polyline)\n",
    "    \n",
    "        #display(dropdown)\n",
    "        #display(button)\n",
    "        \n",
    "        # Print the route information\n",
    "    for position in routes[selected_route]:\n",
    "            trip_id, dep_stop, dep_time, arr_stop, arr_time, ttype, conf = position\n",
    "            dep_stop_name = stops_info_dict[dep_stop][0]\n",
    "            arr_stop_name = stops_info_dict[arr_stop][0]\n",
    "            print(f'Depart from: {dep_stop_name} at {dep_time.strftime(\"%H:%M:%S\")}, arrive to {arr_stop_name} at {arr_time.strftime(\"%H:%M:%S\")} by {ttype}')\n",
    "        \n",
    "    confidence = routes[selected_route][0][6]  # Assuming confidence is the same for all positions in the route\n",
    "    print(f\"Route Confidence: {confidence*100}%\")\n",
    "    map_route.save('map.html')\n",
    "    #display((map_route))\n",
    "\n",
    "dropdown = widgets.Dropdown(options=list(range(1, len(routes) + 1)), description='Select Route:')\n",
    "button = widgets.Button(description='Show Route')\n",
    "display(dropdown)\n",
    "display(button)\n",
    "    \n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638511e-32f1-4eed-aa2d-b8a2de1632a0",
   "metadata": {},
   "source": [
    "#### 4.2 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299c0a0-80fa-4279-a29a-623725dfac38",
   "metadata": {},
   "source": [
    "We will end our work with trying to see how accurate our method is and what are thus the downsides and positive points of what we did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19089fe-4db7-458e-9166-452f3fef9b5c",
   "metadata": {},
   "source": [
    "Let us start with the following example : we go from Zürich Waidspital to Zürich Oerlikon, on a Wednesday, and we want to arrive no later than 10h30, as shown below :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b3b81-841b-422c-9784-37daab1dab03",
   "metadata": {},
   "source": [
    "<img src=\"../figs/first_validation.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad40fa7-11df-4d17-81b1-3b5855e71bf5",
   "metadata": {},
   "source": [
    "The first route (knowing that they're sorted by Latest departure time, taking the Q value into account as well as the walking distance), the first route outputed by our method is the following :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319e602-6332-40e1-bce8-187d792b2a06",
   "metadata": {},
   "source": [
    "<img src=\"../figs/first_validation_route.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b094b-0662-4875-b430-e005d82f5947",
   "metadata": {},
   "source": [
    "The confidence of this route is very good and we see that not many changes are forced upon the user. Moreover, when looking at the SBB CFF, we can see that for the same parameters the outputed route is the following :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f313c62-ca8f-4152-ae40-d3f14be2cbf5",
   "metadata": {},
   "source": [
    "<img src=\"../figs/first_validation_sbb.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e946e-a4ef-4bef-a9d7-674429c90ca1",
   "metadata": {},
   "source": [
    "We thus see that the two routes are actually the same : only the walking duration at the very end changes (the SBB CFF app says 4min of travelling time is required) but we can assume this is due to our approximate footpaths calculations. Other than that, the journey seems to be the same. In reality, the SBB CFF app also proposes, to the user, a route arriving at 10:30 at destination (at that also leaves 7mins later). However, it is not contained in our list of routes. Knowing that the arrival time is <= to 10:30 and that our walking distances seem to be smaller than what's previsioned by the SBB CFF app in that case, we could have assumed that it was removed because of a Q value being too small, the trip maybe being too risky. In reality, even when setting a minimal Q value, the trip is not outputed by our method. This could be due to some shorthandings with regard to the walking distances or for precision of our algorithm.\n",
    "\n",
    "Nonetheless, this result (not being the sole example of such a behaviour of our algorithm) is very encouraging and indicates that our method is able to give pretty accurate results to the user. \n",
    "\n",
    "\n",
    "Let's now see what happens for a longer trip. To illustrate, we select the following parameters :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d7692-7bfb-445b-8e66-305da150e06e",
   "metadata": {},
   "source": [
    "<img src=\"../figs/scd_validation_params.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53610d0-f525-412f-9dd2-bd1dd2d31faf",
   "metadata": {},
   "source": [
    "The outputed route is :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98ebdb-a54d-44e9-9461-a8207256e2ba",
   "metadata": {},
   "source": [
    "<img src=\"../figs/scd_validation_route.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45634fdc-c523-41c7-8518-496f0fe53abf",
   "metadata": {},
   "source": [
    "One of the proposed SBB CFF trips is :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030dc9a-5405-42cc-bf09-8f253f1a7078",
   "metadata": {},
   "source": [
    "<img src=\"../figs/scd_validation_sbb.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6df64-dce9-458b-8473-f8ab248ea8d1",
   "metadata": {},
   "source": [
    "If we look attentively, we can see that the routes are actually the same until the last transfer. The SBB CFF app indicates to the user to stay in the last tram until Horgen, while our algorithm advises the user to get out at Zürich Enge and take another connection. However, we can observe that our results is not too far of the reality and can be considered as satisfying. The only next route outputed by the SBB CFF arrives at 14:30, which is most likely too risky to be considered.\n",
    "\n",
    "This is most likely seen with long distance transports : in our case, the short journeys seem to work pretty well but some differences may occur between the optimal routes given by the state of the art journey planners. Overall, our results are still pretty good. It also happens that no routes are found between stops, while the SBB CFF app says that some trips exist. This could be due to the limitations of our algorithm, but could also be due to the manner in which we computed our delays, maybe not allowing some connections \"too much\" while they're not that risky in general. This could also be due to our algorithm method : if we recall, we said that we were severing each trip_id at a time for a certain departure time, trying to find routes not using this trip. However, this might be not optimal and, our case, remove some routes that would have taken a removed trip differently (i.e not until the end, or en route, etc.). This is also one of the limitations of our method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced85237-a4d4-42ab-a5d6-3cf739f21eac",
   "metadata": {},
   "source": [
    "As we didn't focus on the computational optimization of our algorithm after choosing the CSA as a basis, another important point to consider, as you've been able to see if you ran the query cell with these parameters, is that the execution time is very long (~2 minutes), which is symptomatic of we try to find routes linking two stops that are really far away from each other. In our case, it is not that much of problem in the sense that we are not students running a project and we can afford to wait a bit. However, in a real-case scenario, having to wait that much to get results is maybe not really wishable for a user-friendly experience, and this is one of the limitations of our method. This is most likely due to the number of departure times considered and way in which we force our algorithm to take several routes into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5118c3-2946-43c0-a507-2bb4ce7a5c48",
   "metadata": {},
   "source": [
    "The delays did not seem to vary much between the stops. For the first example we took earlier, changing the arrival time for 17:30, what we expect being peak hours, has changed the probability of the trips by a fine margin, but the algorithm still find confident routes. This might be due to the assumptions we made when computing the delays.\n",
    "\n",
    "In the same manner, choosing the departure time as Friday between the same query on different weekdays did not change anything for the first example we took earlier. We can assume that this is most likely reasonable as, on weekdays and considering only usual trips on the schedule, there shouldn't be any differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bce3d-51ea-49ad-8c73-93c5bf678f7c",
   "metadata": {},
   "source": [
    "To conclude, we can say that our method outputs overall satisfying results : many trips are predicted accurately even if some trips do not follow the optimal routes found by the state-of-the-art planners. Concerning the delays, they are indeed taken into account and outputing some interesting Q values : it seems that some trips are not considered thanks to this, even if we did not make 100% sure it was the case, due to project-ending time constraints. However, they do not seem to render some trips absolutely impossible during peak hours for instance. There are still some questions to be answered as, due to project-ending time constraints, we have not been able to test many different things deeply such as an observation of a same trip with many different Q values, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4729-daf2-49f8-b76e-c405bb6f8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark cleanup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
